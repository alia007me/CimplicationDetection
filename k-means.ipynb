{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878 entries, 0 to 877\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   ID             878 non-null    int64  \n",
      " 1   age            878 non-null    int64  \n",
      " 2   Pedicle        878 non-null    int64  \n",
      " 3   Breast Wieght  878 non-null    int64  \n",
      " 4   SNN            878 non-null    int64  \n",
      " 5   PMH            878 non-null    int64  \n",
      " 6   Smoker         876 non-null    float64\n",
      " 7   Minor          876 non-null    object \n",
      " 8   Major          876 non-null    object \n",
      " 9   BMI            878 non-null    int64  \n",
      " 10  Complication   878 non-null    int64  \n",
      "dtypes: float64(1), int64(8), object(2)\n",
      "memory usage: 75.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   ID  age  Pedicle  Breast Wieght  SNN  PMH  Smoker Minor Major  BMI  \\\n",
       " 0   1    2        4              1    1    0     0.0     0     0    1   \n",
       " 1   2    2        1              2    1    1     1.0     1     0    1   \n",
       " 2   3    1        1              2    2    0     0.0     1     0    2   \n",
       " 3   4    1        1              2    2    2     0.0     1     0    3   \n",
       " 4   5    1        1              2    1    0     0.0     0     0    2   \n",
       " \n",
       "    Complication  \n",
       " 0             0  \n",
       " 1             4  \n",
       " 2             3  \n",
       " 3             1  \n",
       " 4             0  ,\n",
       " None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded data to inspect its structure and content\n",
    "file_path = 'DataSource.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset and its summary\n",
    "data.head(), data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SarayeTell\\AppData\\Local\\Temp\\ipykernel_102748\\862130409.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_features['Smoker'].fillna(data_features['Smoker'].mean(), inplace=True)\n",
      "C:\\Users\\SarayeTell\\AppData\\Local\\Temp\\ipykernel_102748\\862130409.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_features['Minor'].fillna(data_features['Minor'].mode()[0], inplace=True)\n",
      "C:\\Users\\SarayeTell\\AppData\\Local\\Temp\\ipykernel_102748\\862130409.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_features['Major'].fillna(data_features['Major'].mode()[0], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>Pedicle</th>\n",
       "      <th>Breast Wieght</th>\n",
       "      <th>SNN</th>\n",
       "      <th>PMH</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Minor</th>\n",
       "      <th>Major</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>3.137604</td>\n",
       "      <td>-1.349841</td>\n",
       "      <td>-1.363345</td>\n",
       "      <td>-0.402925</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>-0.705996</td>\n",
       "      <td>-0.130613</td>\n",
       "      <td>-1.304547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>-0.474480</td>\n",
       "      <td>-0.076844</td>\n",
       "      <td>-1.363345</td>\n",
       "      <td>0.215551</td>\n",
       "      <td>6.549635</td>\n",
       "      <td>1.388140</td>\n",
       "      <td>-0.130613</td>\n",
       "      <td>-1.304547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.009128</td>\n",
       "      <td>-0.474480</td>\n",
       "      <td>-0.076844</td>\n",
       "      <td>-0.057983</td>\n",
       "      <td>-0.402925</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>1.388140</td>\n",
       "      <td>-0.130613</td>\n",
       "      <td>0.099120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.009128</td>\n",
       "      <td>-0.474480</td>\n",
       "      <td>-0.076844</td>\n",
       "      <td>-0.057983</td>\n",
       "      <td>0.834026</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>1.388140</td>\n",
       "      <td>-0.130613</td>\n",
       "      <td>1.502787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.009128</td>\n",
       "      <td>-0.474480</td>\n",
       "      <td>-0.076844</td>\n",
       "      <td>-1.363345</td>\n",
       "      <td>-0.402925</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>-0.705996</td>\n",
       "      <td>-0.130613</td>\n",
       "      <td>0.099120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       age   Pedicle  Breast Wieght       SNN       PMH    Smoker  \\\n",
       "0   1  0.799065  3.137604      -1.349841 -1.363345 -0.402925 -0.153029   \n",
       "1   2  0.799065 -0.474480      -0.076844 -1.363345  0.215551  6.549635   \n",
       "2   3 -1.009128 -0.474480      -0.076844 -0.057983 -0.402925 -0.153029   \n",
       "3   4 -1.009128 -0.474480      -0.076844 -0.057983  0.834026 -0.153029   \n",
       "4   5 -1.009128 -0.474480      -0.076844 -1.363345 -0.402925 -0.153029   \n",
       "\n",
       "      Minor     Major       BMI  \n",
       "0 -0.705996 -0.130613 -1.304547  \n",
       "1  1.388140 -0.130613 -1.304547  \n",
       "2  1.388140 -0.130613  0.099120  \n",
       "3  1.388140 -0.130613  1.502787  \n",
       "4 -0.705996 -0.130613  0.099120  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Drop the 'Complication' column as it's the result column\n",
    "data_features = data.drop(columns=['Complication'])\n",
    "\n",
    "# Handle missing values: Fill numerical column 'Smoker' with its mean\n",
    "data_features['Smoker'].fillna(data_features['Smoker'].mean(), inplace=True)\n",
    "\n",
    "# Fill categorical columns 'Minor' and 'Major' with their mode\n",
    "data_features['Minor'].fillna(data_features['Minor'].mode()[0], inplace=True)\n",
    "data_features['Major'].fillna(data_features['Major'].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical columns 'Minor' and 'Major'\n",
    "label_encoder = LabelEncoder()\n",
    "data_features['Minor'] = label_encoder.fit_transform(data_features['Minor'])\n",
    "data_features['Major'] = label_encoder.fit_transform(data_features['Major'])\n",
    "\n",
    "# Normalize the data (excluding the 'ID' column, which is just an identifier)\n",
    "scaler = StandardScaler()\n",
    "columns_to_scale = data_features.drop(columns=['ID']).columns\n",
    "data_features[columns_to_scale] = scaler.fit_transform(data_features[columns_to_scale])\n",
    "\n",
    "# Display the preprocessed data\n",
    "data_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   ID  Cluster\n",
       " 0   1        7\n",
       " 1   2        5\n",
       " 2   3        3\n",
       " 3   4        3\n",
       " 4   5        4,\n",
       " Cluster\n",
       " 4    181\n",
       " 1    175\n",
       " 3    165\n",
       " 8    101\n",
       " 2     99\n",
       " 0     63\n",
       " 7     56\n",
       " 5     20\n",
       " 6     18\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Set the number of clusters to 9 and fit the K-means model\n",
    "kmeans = KMeans(n_clusters=9, random_state=42)\n",
    "data_features['Cluster'] = kmeans.fit_predict(data_features.drop(columns=['ID']))\n",
    "\n",
    "# Add the cluster assignments to the dataset and display the cluster counts\n",
    "cluster_counts = data_features['Cluster'].value_counts()\n",
    "\n",
    "data_features[['ID', 'Cluster']].head(), cluster_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SarayeTell\\AppData\\Local\\Temp\\ipykernel_102748\\3521228924.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  new_data['Smoker'].fillna(data_features['Smoker'].mean(), inplace=True)\n",
      "C:\\Users\\SarayeTell\\AppData\\Local\\Temp\\ipykernel_102748\\3521228924.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  new_data['Minor'].fillna(data_features['Minor'].mode()[0], inplace=True)\n",
      "C:\\Users\\SarayeTell\\AppData\\Local\\Temp\\ipykernel_102748\\3521228924.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  new_data['Major'].fillna(data_features['Major'].mode()[0], inplace=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- Cluster\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Example: Predicting clusters for the first 5 rows of the original dataset as test data\u001b[39;00m\n\u001b[0;32m     33\u001b[0m test_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComplication\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 34\u001b[0m predicted_clusters \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_encoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicted_clusters)\n",
      "Cell \u001b[1;32mIn[12], line 29\u001b[0m, in \u001b[0;36mpredict_clusters\u001b[1;34m(new_data, model, scaler, label_encoder_minor, label_encoder_major)\u001b[0m\n\u001b[0;32m     26\u001b[0m new_data[columns_to_scale] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(new_data[columns_to_scale])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Predict clusters\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComplication\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns_to_scale\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Match column names precisely\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_data\n",
      "File \u001b[1;32mc:\\Users\\SarayeTell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1085\u001b[0m, in \u001b[0;36m_BaseKMeans.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict the closest cluster each sample in X belongs to.\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m \n\u001b[0;32m   1069\u001b[0m \u001b[38;5;124;03mIn the vector quantization literature, `cluster_centers_` is called\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;124;03m    Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1085\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_test_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[38;5;66;03m# sample weights are not used by predict but cython helpers expect an array\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\SarayeTell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:944\u001b[0m, in \u001b[0;36m_BaseKMeans._check_test_data\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_test_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m--> 944\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[1;32mc:\\Users\\SarayeTell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[0;32m   2836\u001b[0m     _estimator,\n\u001b[0;32m   2837\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2843\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m   2844\u001b[0m ):\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[0;32m   2846\u001b[0m \n\u001b[0;32m   2847\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2917\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m   2918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2919\u001b[0m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2920\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[0;32m   2921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[1;32mc:\\Users\\SarayeTell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2777\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m   2775\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2777\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- Cluster\n"
     ]
    }
   ],
   "source": [
    "def predict_clusters(new_data, model, scaler, label_encoder_minor, label_encoder_major):\n",
    "    \"\"\"\n",
    "    Preprocesses and predicts the cluster for new data points.\n",
    "    \n",
    "    Parameters:\n",
    "        new_data (DataFrame): The new data to be clustered.\n",
    "        model (KMeans): The trained k-means model.\n",
    "        scaler (StandardScaler): The scaler used to normalize data.\n",
    "        label_encoder_minor (LabelEncoder): Encoder for 'Minor' column.\n",
    "        label_encoder_major (LabelEncoder): Encoder for 'Major' column.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: New data with predicted clusters.\n",
    "    \"\"\"\n",
    "    # Handle missing values\n",
    "    new_data['Smoker'].fillna(data_features['Smoker'].mean(), inplace=True)\n",
    "    new_data['Minor'].fillna(data_features['Minor'].mode()[0], inplace=True)\n",
    "    new_data['Major'].fillna(data_features['Major'].mode()[0], inplace=True)\n",
    "    \n",
    "    # Encode categorical columns\n",
    "    new_data['Minor'] = label_encoder_minor.transform(new_data['Minor'])\n",
    "    new_data['Major'] = label_encoder_major.transform(new_data['Major'])\n",
    "    \n",
    "    # Normalize numerical columns (excluding 'ID')\n",
    "    columns_to_scale = data_features.drop(columns=['ID', 'Cluster']).columns  # Use the original columns from training\n",
    "    new_data[columns_to_scale] = scaler.transform(new_data[columns_to_scale])\n",
    "    \n",
    "    # Predict clusters\n",
    "    new_data['Complication'] = model.predict(new_data[columns_to_scale])  # Match column names precisely\n",
    "    return new_data\n",
    "\n",
    "# Example: Predicting clusters for the first 5 rows of the original dataset as test data\n",
    "test_data = data.iloc[:5].drop(columns=['Complication'])\n",
    "predicted_clusters = predict_clusters(test_data, kmeans, scaler, label_encoder, label_encoder)\n",
    "print(predicted_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
